---
title: "Preface: Gestural Interaction"
date: 2013-02-13 17:48
tags: [gesture]
template: post
---

### A New Neighbor in Town

Using a gesture as a primary interaction method started from the game industry. (Nintendo Wii(2006), Microsoft Kinect(2010), Sony PSMove(2010)) Although several techniques were competitively deployed to implement the gesture recognition, the objective was clearly set for those different platforms: creating novel gaming experience. This phenomenon heralded the ear of gesture interaction is near demonstrating its potential in casual computing.

We had obtained the product first without knowing where it would be heading. The movement was initiated by the developer community: weekend hackers started producing amazing demos drawing more attention from the corporates. The open source frameworks absorbed the gesture as an essential feature one by one. As time of writing, it is a known fact that the biggest computing companies had already acquired multiple startups to put the gesture recognition in their future plan.

### Proxemics and Yard-scale computing

The awakening in the academia was also inevitable. Various HCI courses on this topic were introduced in the hope of establishing the new research area around it. HCI researchers consequently began to analyze this novel interaction practice from the academic perspective. Some concepts from old days were revisited by newly introduced technology. Among many other things, Proxemics, the idea coined by Edward T. Hall in 1963, and the yard scale (meter-sized) computing, a part of "ubiquitous computing" by the HCI legend Mark Weiser in 1988; those two ideas were the most relevant and amazingly visionary from my view.

The common denominator of these two concepts is **distance**. This computing paradigm differentiates itself from the others such as smart phones, tablets, and desktops with its variety of distance. This requires a complete redesign of the system: **control**, **content** and **presentation**.

Obviously the close-range methods do not work well in the yard scale; typing keys, dragging mouse, touching and swiping with fingers are almost useless with a large screen display. Even its social aspect is distinct from others; a big television is supposed to be shared by multiple users. It is an extremely communal device and working on private data with it is quite the opposite of its purpose. The distance and the viewing angle between user and the system yields very dynamic situations exacerbating the visibility of content. Therefore the conventional content presentation will lose its efficiency.

### Gesture to the rescue, but with the side kick

The gesture on the yard scale computing undoubtedly offers better user experience. There are some reasons for it: the interaction time span is short. It allows user to interact directly with the system, not with its remote control. The complexity of tasks on the system is quite minimal. However, it lacks one immensely important element of interaction: __the haptic feedback__. Performing a gesture without proper feedback from the system is almost like dancing without music. Due to the lack of physical contact with the system, finding a rightful alternative is a critical mission.

The first and foremost thing that many people tried is the visual feedback. As previously mentioned, the design strategy for this new media must be redefined from scratch. To put it bluntly, skeuomorphic buttons, knobs and sliders on the screen will not work any more. Moreover, the dynamic nature of distance and angle between users and the system constraints visual efficiency. Using vision is not good enough as it worked on the other platforms.

Thus I claim that the auditory feedback can be a strong candidate as a primary feedback or the best accompaniment for limited vision. Sound does not suffer from the distance and angle. The relationship between physical activity and the sound associated with the gesture makes the user experience more intuitive. The sensitivity and the resolution on human hearing system are surprisingly high. So many things to explore.

### The end of beginning

The visual-centric design of almost every medium virtually makes it harder to try sonic interaction on the system since the visual interaction has been known as "the best bang for the buck" for decades. Besides, the nature of smaller scale platform has suppressed the usage of auditory feedback because of privacy issues and the social context.

My doctoral research on this merely starts here. I see a huge opportunity in orchestrating the gesture, the sound and the yard scale device. The research has to be conducted from every possible angle: prototype design, experimentation on human subjects, implementation and evaluation of the actual system. My journey to gesture already had begun in the last summer 2012, but I put some efforts to  organize ideas by writing up here.